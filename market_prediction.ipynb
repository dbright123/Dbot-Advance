{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import seaborn as sns\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def engineer_features(df):\n",
    "    df['time'] = pd.to_datetime(df['time'], unit='s', errors='coerce')\n",
    "    df['month'] = df['time'].dt.month\n",
    "\n",
    "    # Extract day of the month (1-31)\n",
    "    df['day'] = df['time'].dt.day\n",
    "\n",
    "\n",
    "    # --- New Additions ---\n",
    "    # Extract hour (0-23)\n",
    "    #df['hour'] = df['time'].dt.hour\n",
    "\n",
    "    # Extract minute (0-59)\n",
    "    #df['minute'] = df['time'].dt.minute\n",
    "\n",
    "\n",
    "\n",
    "    # --- End of New Additions ---\n",
    "\n",
    "    # 3. Remove the original 'time' column\n",
    "    df = df.drop(columns=['time'])\n",
    "    # --- Clean up and drop NaNs (first ~200 rows) ---\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def identify_support_resistance(df, n_clusters=5):\n",
    "    \"\"\"Use K-Means clustering to identify support and resistance levels\"\"\"\n",
    "    prices = df['close'].values.reshape(-1, 1)\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    df['price_cluster'] = kmeans.fit_predict(prices)\n",
    "    \n",
    "    # Get cluster centers (support/resistance levels)\n",
    "    cluster_centers = sorted(kmeans.cluster_centers_.flatten())\n",
    "    \n",
    "    # Assign nearest cluster center to each row\n",
    "    df['nearest_sr_level'] = df['close'].apply(\n",
    "        lambda x: min(cluster_centers, key=lambda level: abs(level - x))\n",
    "    )\n",
    "    \n",
    "    return df, cluster_centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_labels(df, cluster_centers, tolerance=0.0005):\n",
    "    \"\"\"\n",
    "    Create buy/sell labels based on price action around support/resistance\n",
    "    Label 0: Hold/No action\n",
    "    Label 1: Buy signal\n",
    "    Label 2: Sell signal\n",
    "    \"\"\"\n",
    "    labels = np.zeros(len(df))\n",
    "    \n",
    "    # Sort cluster centers to identify support and resistance\n",
    "    sr_levels = sorted(cluster_centers)\n",
    "    \n",
    "    for i in range(1, len(df) - 1):\n",
    "        current_price = df.iloc[i]['close']\n",
    "        prev_price = df.iloc[i-1]['close']\n",
    "        next_price = df.iloc[i+1]['close']\n",
    "        \n",
    "        # Find nearest support and resistance\n",
    "        lower_levels = [level for level in sr_levels if level < current_price]\n",
    "        upper_levels = [level for level in sr_levels if level > current_price]\n",
    "        \n",
    "        support = lower_levels[-1] if lower_levels else sr_levels[0]\n",
    "        resistance = upper_levels[0] if upper_levels else sr_levels[-1]\n",
    "        \n",
    "        # Buy signal (1): Price at support and moving up to resistance\n",
    "        if abs(current_price - support) <= tolerance * current_price:\n",
    "            # Check if price moves towards resistance in next periods\n",
    "            future_high = df.iloc[i:min(i+20, len(df))]['high'].max()\n",
    "            if future_high >= resistance * (1 - tolerance):\n",
    "                labels[i] = 1\n",
    "        \n",
    "        # Sell signal (2): Price at resistance and moving down\n",
    "        elif abs(current_price - resistance) <= tolerance * current_price:\n",
    "            # Check if price moves down\n",
    "            future_low = df.iloc[i:min(i+20, len(df))]['low'].min()\n",
    "            if future_low <= support * (1 + tolerance):\n",
    "                labels[i] = 2\n",
    "        \n",
    "        # Breakout buy (1): Price breaks resistance upward\n",
    "        elif prev_price < resistance and current_price > resistance:\n",
    "            # Confirm breakout\n",
    "            if next_price > resistance:\n",
    "                labels[i] = 1\n",
    "        \n",
    "        # Breakdown sell (2): Price breaks support downward\n",
    "        elif prev_price > support and current_price < support:\n",
    "            # Confirm breakdown\n",
    "            if next_price < support:\n",
    "                labels[i] = 2\n",
    "    \n",
    "    df['label'] = labels.astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_technical_indicators(df):\n",
    "    \"\"\"Add RSI, MACD, and other technical indicators\"\"\"\n",
    "    \n",
    "    # RSI (Relative Strength Index)\n",
    "    def calculate_rsi(data, period=14):\n",
    "        delta = data.diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=period).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=period).mean()\n",
    "        rs = gain / loss\n",
    "        rsi = 100 - (100 / (1 + rs))\n",
    "        return rsi\n",
    "    \n",
    "    df['rsi'] = calculate_rsi(df['close'])\n",
    "    \n",
    "    # MACD (Moving Average Convergence Divergence)\n",
    "    exp1 = df['close'].ewm(span=12, adjust=False).mean()\n",
    "    exp2 = df['close'].ewm(span=26, adjust=False).mean()\n",
    "    df['macd'] = exp1 - exp2\n",
    "    df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()\n",
    "    df['macd_hist'] = df['macd'] - df['macd_signal']\n",
    "    \n",
    "    # Moving Averages\n",
    "    df['sma_20'] = df['close'].rolling(window=20).mean()\n",
    "    df['sma_50'] = df['close'].rolling(window=50).mean()\n",
    "    df['ema_12'] = df['close'].ewm(span=12, adjust=False).mean()\n",
    "    \n",
    "    # Bollinger Bands\n",
    "    df['bb_middle'] = df['close'].rolling(window=20).mean()\n",
    "    bb_std = df['close'].rolling(window=20).std()\n",
    "    df['bb_upper'] = df['bb_middle'] + (bb_std * 2)\n",
    "    df['bb_lower'] = df['bb_middle'] - (bb_std * 2)\n",
    "    \n",
    "    # ATR (Average True Range)\n",
    "    high_low = df['high'] - df['low']\n",
    "    high_close = np.abs(df['high'] - df['close'].shift())\n",
    "    low_close = np.abs(df['low'] - df['close'].shift())\n",
    "    ranges = pd.concat([high_low, high_close, low_close], axis=1)\n",
    "    true_range = np.max(ranges, axis=1)\n",
    "    df['atr'] = true_range.rolling(14).mean()\n",
    "    \n",
    "    # Momentum\n",
    "    df['momentum'] = df['close'] - df['close'].shift(4)\n",
    "    \n",
    "    # Volume indicators\n",
    "    df['volume_sma'] = df['tick_volume'].rolling(window=20).mean()\n",
    "    df['volume_ratio'] = df['tick_volume'] / df['volume_sma']\n",
    "    \n",
    "    # Price rate of change\n",
    "    df['roc'] = ((df['close'] - df['close'].shift(10)) / df['close'].shift(10)) * 100\n",
    "    \n",
    "    # Drop rows with NaN values\n",
    "    df = df.dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_signals(df, cluster_centers):\n",
    "    \"\"\"Plot price chart with buy/sell signals\"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    \n",
    "    # Plot close price\n",
    "    ax.plot(df.index, df['close'], label='Close Price', color='blue', alpha=0.6)\n",
    "    \n",
    "    # Plot support/resistance levels\n",
    "    for level in cluster_centers:\n",
    "        ax.axhline(y=level, color='gray', linestyle='--', alpha=0.3)\n",
    "    \n",
    "    # Plot buy signals\n",
    "    buy_signals = df[df['label'] == 1]\n",
    "    ax.scatter(buy_signals.index, buy_signals['close'], \n",
    "               color='green', marker='^', s=100, label='Buy Signal', zorder=5)\n",
    "    \n",
    "    # Plot sell signals\n",
    "    sell_signals = df[df['label'] == 2]\n",
    "    ax.scatter(sell_signals.index, sell_signals['close'], \n",
    "               color='red', marker='v', s=100, label='Sell Signal', zorder=5)\n",
    "    \n",
    "    ax.set_xlabel('Index')\n",
    "    ax.set_ylabel('Price')\n",
    "    ax.set_title('Trading Signals: Buy and Sell Points')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('trading_signals.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nSignal Distribution:\")\n",
    "    print(f\"Hold/No Action (0): {len(df[df['label'] == 0])}\")\n",
    "    print(f\"Buy Signals (1): {len(df[df['label'] == 1])}\")\n",
    "    print(f\"Sell Signals (2): {len(df[df['label'] == 2])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classification_models(df):\n",
    "    \"\"\"Train multiple classification models\"\"\"\n",
    "    \n",
    "    # Prepare features and labels\n",
    "    feature_cols = ['open', 'high', 'low', 'close', 'tick_volume', 'spread',\n",
    "                    'hour', 'minute', 'day', 'month', 'day_of_week',\n",
    "                    'rsi', 'macd', 'macd_signal', 'macd_hist',\n",
    "                    'sma_20', 'sma_50', 'ema_12',\n",
    "                    'bb_upper', 'bb_middle', 'bb_lower', 'atr',\n",
    "                    'momentum', 'volume_ratio', 'roc', 'price_cluster']\n",
    "    \n",
    "    X = df[feature_cols].values\n",
    "    y = df['label'].values\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42, stratify=y\n",
    "    )\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Define models\n",
    "    models = {\n",
    "        'Random Forest': RandomForestClassifier(n_estimators=100, n_jobs=-1, random_state=42),\n",
    "        'Decision Tree': DecisionTreeClassifier(max_depth=10, random_state=42),\n",
    "        'SVC': SVC(kernel='rbf', random_state=42),\n",
    "        'K-Nearest Neighbors': KNeighborsClassifier(n_neighbors=5, n_jobs=-1),\n",
    "        'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "    }\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TRAINING CLASSIFICATION MODELS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        print(f\"\\nTraining {name}...\")\n",
    "        \n",
    "        # Train\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "        \n",
    "        # Evaluate\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        results[name] = {\n",
    "            'model': model,\n",
    "            'accuracy': accuracy,\n",
    "            'predictions': y_pred,\n",
    "            'confusion_matrix': confusion_matrix(y_test, y_pred)\n",
    "        }\n",
    "        \n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        print(f\"\\nClassification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(results[name]['confusion_matrix'], annot=True, fmt='d', cmap='Blues')\n",
    "        plt.title(f'Confusion Matrix - {name}')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.savefig(f'confusion_matrix_{name.replace(\" \", \"_\")}.png', dpi=300)\n",
    "        plt.show()\n",
    "    \n",
    "    return results, X_train_scaled, X_test_scaled, y_train, y_test, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_deep_neural_network(X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Train a deep neural network for classification\"\"\"\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"TRAINING DEEP NEURAL NETWORK\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Convert labels to categorical\n",
    "    num_classes = len(np.unique(y_train))\n",
    "    y_train_cat = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test_cat = keras.utils.to_categorical(y_test, num_classes)\n",
    "    \n",
    "    # Build model\n",
    "    model = keras.Sequential([\n",
    "        layers.Input(shape=(X_train.shape[1],)),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(16, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer='adam',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    print(\"\\nModel Architecture:\")\n",
    "    model.summary()\n",
    "    \n",
    "    # Train\n",
    "    history = model.fit(\n",
    "        X_train, y_train_cat,\n",
    "        validation_split=0.2,\n",
    "        epochs=50,\n",
    "        batch_size=32,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred_proba = model.predict(X_test)\n",
    "    y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    print(f\"\\n\\nDeep Neural Network Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"\\nClassification Report:\\n{classification_report(y_test, y_pred)}\")\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens')\n",
    "    plt.title('Confusion Matrix - Deep Neural Network')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.savefig('confusion_matrix_DNN.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot training history\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    ax1.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    ax1.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax1.set_title('Model Accuracy')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Accuracy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "    \n",
    "    ax2.plot(history.history['loss'], label='Training Loss')\n",
    "    ax2.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax2.set_title('Model Loss')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('dnn_training_history.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    return model, accuracy, cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"TRADING SIGNAL CLASSIFICATION SYSTEM\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Step 1: Load data from Excel\n",
    "print(\"\\nStep 1: Loading data from Excel file...\")\n",
    "t_symbol = [\"GBPUSD\"]\n",
    "n = 0\n",
    "m_label = \"Generated\"+t_symbol[n]\n",
    "\n",
    "df = pd.read_csv(m_label+ \" dbot.csv\")[['time','close','volume']]\n",
    "df = engineer_features(df)\n",
    "df\n",
    "\n",
    "print(f\"Data loaded: {len(df)} rows\")\n",
    "print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "max_val = df.max()\n",
    "joblib.dump(max_val,m_label+\" max_val.joblib\")\n",
    "print(max_val)\n",
    "df = df/max_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Identify support/resistance\n",
    "print(\"\\nStep 2: Identifying support and resistance levels...\")\n",
    "df, cluster_centers = identify_support_resistance(df, n_clusters=5)\n",
    "print(f\"Support/Resistance levels: {cluster_centers}\")\n",
    "\n",
    "# Step 3: Create labels\n",
    "print(\"\\nStep 3: Creating buy/sell labels...\")\n",
    "df = create_labels(df, cluster_centers)\n",
    "\n",
    "# Step 4: Add technical indicators\n",
    "print(\"\\nStep 4: Adding technical indicators...\")\n",
    "df = add_technical_indicators(df)\n",
    "print(f\"Final dataset shape: {df.shape}\")\n",
    "\n",
    "# Step 5: Visualize signals\n",
    "print(\"\\nStep 5: Visualizing trading signals...\")\n",
    "plot_signals(df, cluster_centers)\n",
    "\n",
    "# Step 6: Train classification models\n",
    "print(\"\\nStep 6: Training classification models...\")\n",
    "results, X_train, X_test, y_train, y_test, scaler = train_classification_models(df)\n",
    "\n",
    "# Step 7: Train deep neural network\n",
    "print(\"\\nStep 7: Training deep neural network...\")\n",
    "dnn_model, dnn_accuracy, dnn_cm = train_deep_neural_network(\n",
    "    X_train, X_test, y_train, y_test\n",
    ")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "for name, result in results.items():\n",
    "    print(f\"{name}: {result['accuracy']:.4f}\")\n",
    "print(f\"Deep Neural Network: {dnn_accuracy:.4f}\")\n",
    "\n",
    "print(\"\\nAll models trained successfully!\")\n",
    "print(\"Confusion matrices and plots saved to current directory.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
