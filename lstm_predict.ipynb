{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbright123/Dbot-Advance/blob/main/lstm_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1oCaggK4VKR"
      },
      "outputs": [],
      "source": [
        "import MetaTrader5 as mt5\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btJoWVAx4VKS",
        "outputId": "077d53d7-b8ac-4d3c-9251-3f449e68e0f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MetaTrader5 package author:  MetaQuotes Ltd.\n",
            "MetaTrader5 package version:  5.0.4200\n",
            "True\n",
            "{'login': 213644473, 'trade_mode': 0, 'leverage': 1000, 'limit_orders': 500, 'margin_so_mode': 0, 'trade_allowed': True, 'trade_expert': True, 'margin_mode': 2, 'currency_digits': 2, 'fifo_close': False, 'balance': 200.0, 'credit': 0.0, 'profit': 0.0, 'equity': 200.0, 'margin': 0.0, 'margin_free': 200.0, 'margin_level': 0.0, 'margin_so_call': 25.0, 'margin_so_so': 15.0, 'margin_initial': 0.0, 'margin_maintenance': 0.0, 'assets': 0.0, 'liabilities': 0.0, 'commission_blocked': 0.0, 'name': 'micheal bright omage ', 'server': 'OctaFX-Demo', 'currency': 'USD', 'company': 'Octa Markets Incorporated'}\n",
            "\n",
            "\n",
            "{'community_account': False, 'community_connection': False, 'connected': True, 'dlls_allowed': False, 'trade_allowed': True, 'tradeapi_disabled': False, 'email_enabled': False, 'ftp_enabled': False, 'notifications_enabled': False, 'mqid': False, 'build': 5260, 'maxbars': 100000, 'codepage': 0, 'ping_last': 136559, 'community_balance': 0.0, 'retransmission': 0.0, 'company': 'MetaQuotes Software Corp.', 'name': 'MetaTrader 5', 'language': 'English', 'path': 'C:\\\\Program Files\\\\MetaTrader 5', 'data_path': 'C:\\\\Program Files\\\\MetaTrader 5', 'commondata_path': 'C:\\\\Users\\\\omage\\\\AppData\\\\Roaming\\\\MetaQuotes\\\\Terminal\\\\Common'}\n",
            "\n",
            "\n",
            "280\n"
          ]
        }
      ],
      "source": [
        "print(\"MetaTrader5 package author: \",mt5.__author__)\n",
        "print(\"MetaTrader5 package version: \",mt5.__version__)\n",
        "\n",
        "trade_active = mt5.initialize()\n",
        "\n",
        "print(trade_active)\n",
        "\n",
        "if not trade_active:\n",
        "    print('Initialization failed, check internet connection. You must have Meta Trader 5 installed.')\n",
        "    mt5.shutdown()\n",
        "\n",
        "else:\n",
        "    print(mt5.account_info()._asdict())\n",
        "    print(\"\\n\")\n",
        "    print(mt5.terminal_info()._asdict())\n",
        "    print(\"\\n\")\n",
        "    print(mt5.symbols_total())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ep9xWhDh4VKU",
        "outputId": "31c79ec1-fd31-4335-d881-2db8f23fed61"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "200.0\n",
            "AI is successfully functional\n"
          ]
        }
      ],
      "source": [
        "account = mt5.account_info()\n",
        "terminal = mt5.terminal_info()\n",
        "\n",
        "print(account.equity)\n",
        "\n",
        "if(terminal.connected == True and terminal.trade_allowed == True):\n",
        "    print(\"AI is successfully functional\")\n",
        "else:\n",
        "    print(\"Please make sure metatrade 5 has internet and algo Trade is Turn On\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cm6_C7cwJaFl",
        "outputId": "14ed083f-33ea-49ce-81da-0259753f3a03"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "280\n",
            "Yes  EURUSD\n",
            "Yes  GBPUSD\n",
            "Yes  USDJPY\n",
            "Yes  USDCHF\n",
            "Yes  AUDUSD\n",
            "Yes  NZDUSD\n",
            "Yes  USDCAD\n",
            "Yes  USDMXN\n",
            "Yes  USDZAR\n",
            "Yes  XAGUSD\n",
            "Yes  XAUUSD\n",
            "Yes  XBRUSD\n",
            "Yes  XTIUSD\n",
            "Yes  XNGUSD\n",
            "Yes  BTCUSD\n",
            "Yes  ETHUSD\n",
            "Yes  LTCUSD\n",
            "Yes  XRPUSD\n",
            "Yes  BCHUSD\n",
            "Yes  AAVEUSD\n",
            "Yes  ADAUSD\n",
            "Yes  ALGOUSD\n",
            "Yes  ATOMUSD\n",
            "Yes  AVAXUSD\n",
            "Yes  AXSUSD\n",
            "Yes  BNBUSD\n",
            "Yes  DASHUSD\n",
            "Yes  DOGEUSD\n",
            "Yes  DOTUSD\n",
            "Yes  FILUSD\n",
            "Yes  GRTUSD\n",
            "Yes  ICPUSD\n",
            "Yes  IOTAUSD\n",
            "Yes  LINKUSD\n",
            "Yes  LRCUSD\n",
            "Yes  MANAUSD\n",
            "Yes  NEARUSD\n",
            "Yes  SOLUSD\n",
            "Yes  UNIUSD\n",
            "Yes  ZECUSD\n",
            "Yes  ETCUSD\n",
            "Yes  TRXUSD\n",
            "Yes  FETUSD\n",
            "Yes  ARBUSD\n",
            "Yes  APTUSD\n",
            "Yes  SUIUSD\n",
            "Yes  USDDKK\n",
            "Yes  USDCZK\n",
            "Yes  USDHUF\n",
            "Yes  USDNOK\n",
            "Yes  USDPLN\n",
            "Yes  USDSEK\n",
            "Yes  USDSGD\n",
            "Yes  USDHKD\n",
            "Yes  USDCNH\n",
            "Yes  USDTRY\n",
            "Yes  XBRUSD.Daily\n",
            "Yes  XTIUSD.Daily\n",
            "Yes  BTCUSD.Daily\n",
            "Yes  ETHUSD.Daily\n",
            "Yes  XRPUSD.Daily\n",
            "Yes  LTCUSD.Daily\n",
            "Yes  BCHUSD.Daily\n",
            "Yes  LINKUSD.Daily\n",
            "Yes  SOLUSD.Daily\n",
            "65\n"
          ]
        }
      ],
      "source": [
        "symbols = mt5.symbols_get()\n",
        "print(len(symbols))\n",
        "t_symbol = []\n",
        "for symbol in symbols:\n",
        "    if \"USD\" in symbol.name:\n",
        "        print(\"Yes \", symbol.name)\n",
        "        t_symbol.append(symbol.name)\n",
        "\n",
        "print(len(t_symbol))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PT_T7TBpJaFl"
      },
      "outputs": [],
      "source": [
        "test_symbol = []\n",
        "for t_s in t_symbol:\n",
        "    market = mt5.copy_rates_from_pos(t_s, mt5.TIMEFRAME_H1, 0, 99999)\n",
        "    if(len(market) > 80000):\n",
        "        data = []\n",
        "        for i in range(len(market)):\n",
        "            data.append([market[i][1],market[i][2],market[i][3],market[i][4]])\n",
        "        df = pd.DataFrame(data, columns=[\"open\", \"high\",\"low\", \"close\"])\n",
        "        df.to_csv(\"Generated\"+t_s+\" dbot.csv\", index=False)\n",
        "        test_symbol.append(t_s)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "b4CF7z2N8h2S",
        "outputId": "ecf7e204-67fe-451f-bc5d-d0dcdf4df0ec"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'test_symbol' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3173121947.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mt_s\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_symbol\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmarket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmt5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_rates_from_pos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmt5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTIMEFRAME_D1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarket\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m900\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmarket\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_symbol' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "for t_s in test_symbol:\n",
        "    market = mt5.copy_rates_from_pos(t_s, mt5.TIMEFRAME_D1, 0, 1000)\n",
        "    if(len(market) > 900):\n",
        "        data = []\n",
        "        for i in range(len(market)):\n",
        "            data.append([market[i][1],market[i][2],market[i][3],market[i][4]])\n",
        "        df = pd.DataFrame(data, columns=[\"open\", \"high\",\"low\", \"close\"])\n",
        "        df.to_csv(\"Generated\"+t_s+\" test.csv\", index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjdWs03YJaFm",
        "outputId": "65b3d587-0c44-45ea-8550-33b17d991ad6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['symbol.joblib']"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(t_symbol,\"symbol.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "M8QyUXsy4op6"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "PqACycZPJaFn"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import math\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "tpswK5-7JaFo"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import SGD,Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, BatchNormalization, LayerNormalization, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "e5GJ3N6HJaFo",
        "outputId": "6995d374-b9de-46e2-d0b0-59b7b70184f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'symbol.joblib'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2007119436.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdir_contents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mt_symbol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"symbol.joblib\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/joblib/numpy_pickle.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode, ensure_native_byte_order)\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_native_byte_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mensure_native_byte_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 735\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    736\u001b[0m             with _validate_fileobject_and_memmap(f, filename, mmap_mode) as (\n\u001b[1;32m    737\u001b[0m                 \u001b[0mfobj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'symbol.joblib'"
          ]
        }
      ],
      "source": [
        "# Get the list of all files and directories in the specified path\n",
        "\n",
        "dir_contents = os.listdir(\".\")\n",
        "t_symbol = joblib.load(\"symbol.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G82RO07oi6t1"
      },
      "outputs": [],
      "source": [
        "print(t_symbol)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9Urbl8tJaFp"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Filter the list to include only files, not directories\n",
        "# os.path.join is used to create a full path for isfile() to check\n",
        "files = [item for item in dir_contents]\n",
        "\n",
        "file_target = []\n",
        "test_target = []\n",
        "\n",
        "for filename in files:\n",
        "    for t_s in t_symbol:\n",
        "        if t_s in filename  and \"dbot.csv\" in filename:\n",
        "            print(filename)\n",
        "            file_target.append(filename)\n",
        "            test_target.append(filename.replace(\"dbot\",\"test\"))\n",
        "\n",
        "print(\"----------------------------------------------------\")\n",
        "\n",
        "print(len(file_target))\n",
        "print(len(test_target))\n",
        "train_dfs = []\n",
        "for f_t in file_target:\n",
        "    train_dfs.append(pd.read_csv(f_t))\n",
        "\n",
        "train_dfs_test = []\n",
        "for f_t in test_target:\n",
        "    train_dfs_test.append(pd.read_csv(f_t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94sFD1Kc29tr"
      },
      "outputs": [],
      "source": [
        "display(train_dfs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tOE5gYlbhIFd"
      },
      "outputs": [],
      "source": [
        "display(train_dfs_test[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X-1MEa4L3HwH"
      },
      "outputs": [],
      "source": [
        "print(train_dfs[0].values[:,-1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnvfkDwKJaFp"
      },
      "outputs": [],
      "source": [
        "def create_sequences(data_scaled, seq_len):\n",
        "    \"\"\"\n",
        "    data_scaled: np.array shaped (n_rows, n_features)\n",
        "    returns X (n_samples, seq_len, n_features), y (n_samples, n_features)\n",
        "    where y is the row immediately following the window.\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    n_rows = data_scaled.shape[0]\n",
        "    for i in range(n_rows - seq_len):\n",
        "        X.append(data_scaled[i:i+seq_len])\n",
        "        y.append(data_scaled[i+seq_len])\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    return X, y\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5j_wkyXD5s_s"
      },
      "outputs": [],
      "source": [
        "for i in range(len(train_dfs)):\n",
        "  m_label = file_target[i].replace(\"dbot.csv\",\"\")\n",
        "  train_df = train_dfs[i]\n",
        "  train_df_test = train_dfs_test[i]\n",
        "  print(m_label)\n",
        "  SEQ_LEN = 120 # length of input sequence (timesteps). Typical choices: 30, 60, 90\n",
        "  n_rows, n_features = train_df.values.shape\n",
        "  scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "  #scaler = StandardScaler()\n",
        "  s = scaler.fit_transform(train_df.values[:,-1:])\n",
        "  s1 = scaler.transform(train_df_test.values[:,-1:])\n",
        "\n",
        "  X, y = create_sequences(s, SEQ_LEN)  # X: (n_samples, SEQ_LEN, n_features), y: (n_samples, n_features)\n",
        "  X1, y1 = create_sequences(s, SEQ_LEN)  # X: (n_samples, SEQ_LEN, n_features), y: (n_samples, n_features)\n",
        "\n",
        "  n_samples = X.shape[0]\n",
        "\n",
        "  joblib.dump(scaler, m_label + 'scaler.joblib')\n",
        "\n",
        "\n",
        "\n",
        "  y = y.reshape((y.shape[0],y.shape[1],1))\n",
        "\n",
        "  y1 = y1.reshape((y1.shape[0],y1.shape[1],1))\n",
        "\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0, shuffle=False)\n",
        "  X_val, X_test, y_val,  y_test = train_test_split(X_test, y_test, test_size=0.01, random_state=0, shuffle=False)\n",
        "\n",
        "  seq_len = X_train.shape[1]\n",
        "  n_features = X_train.shape[2]\n",
        "  output_dim = y_train.shape[1]\n",
        "\n",
        "  i = Input(shape=(seq_len, n_features))\n",
        "  X = LSTM(200, return_sequences=True)(i)\n",
        "  X = LSTM(200, return_sequences=True)(X)\n",
        "  X = LSTM(200, return_sequences=True)(X)\n",
        "  X = LSTM(200)(X)\n",
        "  #X = Dropout(0.5)(X)\n",
        "  X = Dense(150, activation=\"relu\")(X)\n",
        "  X = Dropout(0.25)(X)\n",
        "  X = Dense(output_dim)(X)\n",
        "\n",
        "  model = Model(i, X)\n",
        "  model.summary()\n",
        "\n",
        "  es = EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True, verbose=2)\n",
        "  rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=6, min_lr=1e-6, verbose=2)\n",
        "  mc = ModelCheckpoint(m_label + 'lstm_best.keras', monitor='val_loss', save_best_only=True, verbose=2)\n",
        "  model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                loss='mse',\n",
        "                metrics=['mae',tf.keras.metrics.RootMeanSquaredError(),'mape','msle'])\n",
        "  r = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=100,\n",
        "    batch_size=4096,\n",
        "    callbacks=[es, rlr, mc ],\n",
        "    verbose=2\n",
        "\n",
        "  )\n",
        "\n",
        "  plt.title(\"Loss on data\")\n",
        "  plt.plot(r.history['loss'], label=\"loss\")\n",
        "  plt.plot(r.history['val_loss'], label=\"val_loss\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  plt.title(\"MAE on data\")\n",
        "  plt.plot(r.history['mae'], label=\"mae\")\n",
        "  plt.plot(r.history['val_mae'], label=\"val_mae\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  plt.title(\"mape on data\")\n",
        "  plt.plot(r.history['mape'], label=\"mape\")\n",
        "  plt.plot(r.history['val_mape'], label=\"val_mape\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  plt.title(\"msle on data\")\n",
        "  plt.plot(r.history['msle'], label=\"msle\")\n",
        "  plt.plot(r.history['val_msle'], label=\"val_msle\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  plt.title(\"root_mean_squared_error on data\")\n",
        "  plt.plot(r.history['root_mean_squared_error'], label=\"root_mean_squared_error\")\n",
        "  plt.plot(r.history['val_root_mean_squared_error'], label=\"val_root_mean_squared_error\")\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "\n",
        "  best_model = load_model(m_label + 'lstm_best.keras')\n",
        "  y_pred = best_model.predict(X_test)\n",
        "  print(\"R^2 value for \", m_label)\n",
        "  print(r2_score(y_test.reshape((len(y_test),1)), y_pred.reshape((len(y_pred),1))))\n",
        "\n",
        "  plt.figure(figsize=(12, 6))\n",
        "  plt.plot(y_test[:, -1], label='Actual Close Price', color='blue')\n",
        "  plt.plot(y_pred[:, -1], label='Predicted Close Price', color='red', linestyle='--')\n",
        "  plt.title('Actual vs. Predicted Close Price')\n",
        "  plt.xlabel('Time')\n",
        "  plt.ylabel('Close Price')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "  plt.savefig('actual_vs_predicted.png')\n",
        "  plt.show()\n",
        "\n",
        "  y_pred = best_model.predict(X1)\n",
        "  print(\"R^2 value for test \", m_label)\n",
        "  print(r2_score(y1.reshape((len(y1),1)), y_pred.reshape((len(y_pred),1))))\n",
        "\n",
        "  plt.figure(figsize=(12, 6))\n",
        "  plt.plot(y1[:, -1], label='Actual Close Price', color='blue')\n",
        "  plt.plot(y_pred[:, -1], label='Predicted Close Price', color='red', linestyle='--')\n",
        "  plt.title('Actual vs. Predicted Close Price Test')\n",
        "  plt.xlabel('Time')\n",
        "  plt.ylabel('Close Price')\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "  plt.savefig('actual_vs_predicted.png')\n",
        "  plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xjxPQbLgmcI7"
      },
      "outputs": [],
      "source": [
        "!zip -r \"*\" \"archive.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phLewG94CgH8"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "best_model = load_model(m_label + 'lstm_best.keras')\n",
        "    y_pred = best_model.predict(X_test)\n",
        "    print(\"R^2 value for \", m_label)\n",
        "    print(r2_score(y_test.reshape((len(y_test),1)), y_pred.reshape((len(y_pred),1))))\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(y_test[:, -1], label='Actual Close Price', color='blue')\n",
        "    plt.plot(y_pred[:, -1], label='Predicted Close Price', color='red', linestyle='--')\n",
        "    plt.title('Actual vs. Predicted Close Price')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Close Price')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig('actual_vs_predicted.png')\n",
        "    plt.show()\n",
        "\n",
        "    y_pred = best_model.predict(X1)\n",
        "    print(\"R^2 value for test \", m_label)\n",
        "    print(r2_score(y1.reshape((len(y1),1)), y_pred.reshape((len(y_pred),1))))\n",
        "\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(y1[:, -1], label='Actual Close Price', color='blue')\n",
        "    plt.plot(y_pred[:, -1], label='Predicted Close Price', color='red', linestyle='--')\n",
        "    plt.title('Actual vs. Predicted Close Price Test')\n",
        "    plt.xlabel('Time')\n",
        "    plt.ylabel('Close Price')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig('actual_vs_predicted.png')\n",
        "    plt.show()\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6u5b2IWUDm-"
      },
      "outputs": [],
      "source": [
        "dir_contents = os.listdir(\".\")\n",
        "t_symbol = joblib.load(\"symbol.joblib\")\n",
        "# Filter the list to include only files, not directories\n",
        "# os.path.join is used to create a full path for isfile() to check\n",
        "files = [item for item in dir_contents]\n",
        "\n",
        "file_target = []\n",
        "\n",
        "for filename in files:\n",
        "    for t_s in t_symbol:\n",
        "        if t_s in filename and \"lstm_best.keras\" in filename:\n",
        "            print(filename)\n",
        "            #file_target.append(filename)\n",
        "print(\"----------------------------------------------------\")\n",
        "\n",
        "print(len(file_target))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1IK-bCRTSSV"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "best_model = load_model(MODEL_SAVE_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGxCK9h0RKL1"
      },
      "outputs": [],
      "source": [
        "y_pred = best_model.predict(X_test)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_wbrFrlR3a-"
      },
      "outputs": [],
      "source": [
        "print(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRoHAR1nSG1Z"
      },
      "outputs": [],
      "source": [
        "\n",
        "r2_score(y_test.reshape((len(y_test),1)), y_pred.reshape((len(y_pred),1)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4RXPB75_TS6L"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y_test[:, -1], label='Actual Close Price', color='blue')\n",
        "plt.plot(y_pred[:, -1], label='Predicted Close Price', color='red', linestyle='--')\n",
        "plt.title('Actual vs. Predicted Close Price')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Close Price')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('actual_vs_predicted.png')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hwbdScYaBhK"
      },
      "outputs": [],
      "source": [
        "# Save this as plot_forecast.py and run where your model, x_test, y_test (and optional scalers) are available.\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def ensure_2d_preds(preds):\n",
        "    \"\"\"Normalize model.predict outputs to shape (n_samples, n_features).\"\"\"\n",
        "    preds = np.asarray(preds)\n",
        "    if preds.ndim == 3:\n",
        "        # common case: (n_samples, 1, n_features) or (n_samples, seq_len, n_features)\n",
        "        # we assume model outputs final-step predictions if seq_len>1\n",
        "        if preds.shape[1] == 1:\n",
        "            preds = preds[:, 0, :]\n",
        "        else:\n",
        "            preds = preds[:, -1, :]\n",
        "    elif preds.ndim == 1:\n",
        "        preds = preds.reshape(-1, 1)\n",
        "    return preds\n",
        "\n",
        "def plot_test_vs_pred_close(y_test, preds, output_index=-1, figsize=(12,5), savepath=None):\n",
        "    \"\"\"\n",
        "    Plot actual vs predicted for the 'close' column (default last column).\n",
        "    y_test: (n, n_features)\n",
        "    preds: (n, n_features)\n",
        "    \"\"\"\n",
        "    y_test = np.asarray(y_test)\n",
        "    preds = np.asarray(preds)\n",
        "    # normalize shapes\n",
        "    preds = ensure_2d_preds(preds)\n",
        "\n",
        "    actual_close = y_test[:, output_index]\n",
        "    pred_close   = preds[:, output_index]\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.plot(actual_close, label='Actual Close')\n",
        "    plt.plot(pred_close, label='Predicted Close')\n",
        "    plt.xlabel('Time (test index)')\n",
        "    plt.ylabel('Close price')\n",
        "    plt.title('Actual vs Predicted Close Price (test set)')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    if savepath:\n",
        "        plt.savefig(savepath, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n",
        "def recursive_forecast(model, last_window, n_steps=2000):\n",
        "    \"\"\"\n",
        "    Do recursive multi-step forecasting:\n",
        "      - model.predict expects input shape (1, window_len, n_features)\n",
        "      - last_window: shape (window_len, n_features)\n",
        "      - returns array shape (n_steps, n_features)\n",
        "    \"\"\"\n",
        "    last_window = last_window.reshape((len(last_window),1))\n",
        "    if last_window.ndim != 2:\n",
        "        raise ValueError(\"last_window must be 2D: (window_len, n_features)\")\n",
        "\n",
        "    window_len, n_features = last_window.shape\n",
        "    history = last_window.copy()\n",
        "    preds = []\n",
        "    for i in range(n_steps):\n",
        "        x_in = history.reshape(1, window_len, n_features)\n",
        "        p = model.predict(x_in)\n",
        "        p = ensure_2d_preds(p)[0]  # shape: (n_features,)\n",
        "        preds.append(p)\n",
        "        # slide window\n",
        "        history = np.vstack([history[1:], p.reshape(1, n_features)])\n",
        "    return np.vstack(preds)  # shape (n_steps, n_features)\n",
        "\n",
        "def plot_extended_series(y_test, future_preds, output_index=-1, figsize=(14,5), savepath=None):\n",
        "    \"\"\"\n",
        "    Plot the test-close series and appended future predictions as one continuous line.\n",
        "    \"\"\"\n",
        "    actual_close = np.asarray(y_test)[:, output_index]\n",
        "    future_close = np.asarray(future_preds)[:, output_index]\n",
        "    combined = np.concatenate([actual_close, future_close])\n",
        "\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.plot(combined, label='Actual (test) + Forecast (future)')\n",
        "    # mark border between known and forecast\n",
        "    split_index = len(actual_close)\n",
        "    plt.axvline(split_index - 0.5, linestyle='--', linewidth=1)\n",
        "    plt.text(split_index + 5, combined[split_index], ' Forecast starts', va='center')\n",
        "    plt.xlabel('Time (index)')\n",
        "    plt.ylabel('Close price')\n",
        "    plt.title(f'Actual Close (test) and {len(future_close)} Step Forecast')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    if savepath:\n",
        "        plt.savefig(savepath, bbox_inches='tight')\n",
        "    plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IaGU2AJkhpd"
      },
      "outputs": [],
      "source": [
        "# ------------------------------------------------------------\n",
        "# USAGE (example)\n",
        "# ------------------------------------------------------------\n",
        "# Assumptions:\n",
        "# - x_test shape = (n_samples, window_len, n_features) e.g. (6247, 48, 4)\n",
        "# - y_test shape = (n_samples, n_features) e.g. (6247, 4)\n",
        "# - model.predict(x_test) -> (n_samples, n_features) (or shape convertible)\n",
        "#\n",
        "# Optional:\n",
        "# - scaler_X (used during training on inputs) or scaler_y (used on outputs).\n",
        "#   If present, inverse_transform predictions and y_test before plotting.\n",
        "#\n",
        "# Replace these names with your actual variables present in the workspace.\n",
        "\n",
        "# Example (uncomment and run where variables exist):\n",
        "preds_test = best_model.predict(X_test)\n",
        "preds_test = ensure_2d_preds(preds_test)\n",
        "\n",
        "# # 1) plot actual vs predicted (test)\n",
        "plot_test_vs_pred_close(y_test, preds_test, output_index=-1, savepath='test_vs_pred.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnYWb1TVo-4o"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# # 2) recursive forecast next 2000 values starting from last input window:\n",
        "last_window = X_test[-1].reshape((len(X_test[-1]),1))   # shape (window_len, n_features)\n",
        "future_preds = recursive_forecast(best_model, last_window, n_steps=200)\n",
        "future_preds_inv = future_preds\n",
        "\n",
        "# # 3) plot extended series (append future close to test close)\n",
        "plot_extended_series(y_test, future_preds_inv, output_index=-1, savepath='extended_forecast.png')\n",
        "#\n",
        "# # Optional: save future_preds_inv to disk\n",
        "# # np.save('future_preds.npy', future_preds_inv)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}