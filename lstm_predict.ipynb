{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbright123/Dbot-Advance/blob/main/lstm_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Z1oCaggK4VKR"
      },
      "outputs": [],
      "source": [
        "import MetaTrader5 as mt5\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btJoWVAx4VKS",
        "outputId": "077d53d7-b8ac-4d3c-9251-3f449e68e0f3"
      },
      "outputs": [],
      "source": [
        "print(\"MetaTrader5 package author: \",mt5.__author__)\n",
        "print(\"MetaTrader5 package version: \",mt5.__version__)\n",
        "\n",
        "trade_active = mt5.initialize()\n",
        "\n",
        "print(trade_active)\n",
        "\n",
        "if not trade_active:\n",
        "    print('Initialization failed, check internet connection. You must have Meta Trader 5 installed.')\n",
        "    mt5.shutdown()\n",
        "\n",
        "else:\n",
        "    print(mt5.account_info()._asdict())\n",
        "    print(\"\\n\")\n",
        "    print(mt5.terminal_info()._asdict())\n",
        "    print(\"\\n\")\n",
        "    print(mt5.symbols_total())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ep9xWhDh4VKU",
        "outputId": "31c79ec1-fd31-4335-d881-2db8f23fed61"
      },
      "outputs": [],
      "source": [
        "account = mt5.account_info()\n",
        "terminal = mt5.terminal_info()\n",
        "\n",
        "print(account.equity)\n",
        "\n",
        "if(terminal.connected == True or terminal.trade_allowed == True):\n",
        "    print(\"AI is successfully functional\")\n",
        "else:\n",
        "    print(\"Please make sure metatrade 5 has internet and algo Trade is Turn On\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cm6_C7cwJaFl",
        "outputId": "14ed083f-33ea-49ce-81da-0259753f3a03"
      },
      "outputs": [],
      "source": [
        "symbols = mt5.symbols_get()\n",
        "print(len(symbols))\n",
        "t_symbol = []\n",
        "for symbol in symbols:\n",
        "    if \"USD\" in symbol.name:\n",
        "        print(\"Yes \", symbol.name)\n",
        "        t_symbol.append(symbol.name)\n",
        "\n",
        "print(len(t_symbol))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4Nye5Nj2DGW",
        "outputId": "0dec2b90-1041-4a82-ca35-4016bfbf33f0"
      },
      "outputs": [],
      "source": [
        "market = mt5.copy_rates_from_pos(t_symbol[0], mt5.TIMEFRAME_H1, 0, 99999)\n",
        "display(market)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PT_T7TBpJaFl"
      },
      "outputs": [],
      "source": [
        "test_symbol = []\n",
        "for t_s in t_symbol:\n",
        "    market = mt5.copy_rates_from_pos(t_s, mt5.TIMEFRAME_H1, 0, 99999)\n",
        "    if(len(market) > 80000 and market[0][4] < 1):\n",
        "        data = []\n",
        "        for i in range(len(market)):\n",
        "            data.append([market[i][1],market[i][2],market[i][3],market[i][4]])\n",
        "        df = pd.DataFrame(data, columns=[\"open\", \"high\",\"low\", \"close\"])\n",
        "        df.to_csv(\"Generated\"+t_s+\" dbot.csv\", index=False)\n",
        "        test_symbol.append(t_s)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "b4CF7z2N8h2S"
      },
      "outputs": [],
      "source": [
        "\n",
        "for t_s in test_symbol:\n",
        "    market = mt5.copy_rates_from_pos(t_s, mt5.TIMEFRAME_D1, 0, 1000)\n",
        "    if(len(market) > 900):\n",
        "        data = []\n",
        "        for i in range(len(market)):\n",
        "            data.append([market[i][1],market[i][2],market[i][3],market[i][4]])\n",
        "        df = pd.DataFrame(data, columns=[\"open\", \"high\",\"low\", \"close\"])\n",
        "        df.to_csv(\"Generated\"+t_s+\" test.csv\", index=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hjdWs03YJaFm",
        "outputId": "65b3d587-0c44-45ea-8550-33b17d991ad6"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(t_symbol,\"symbol.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M8QyUXsy4op6"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "PqACycZPJaFn"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import math\n",
        "import joblib\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "tpswK5-7JaFo"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import SGD,Adam\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, BatchNormalization, LayerNormalization, Bidirectional\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "from tensorflow.keras.models import load_model\n",
        "import keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "e5GJ3N6HJaFo"
      },
      "outputs": [],
      "source": [
        "# Get the list of all files and directories in the specified path\n",
        "\n",
        "dir_contents = os.listdir(\".\")\n",
        "t_symbol = joblib.load(\"symbol.joblib\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G82RO07oi6t1",
        "outputId": "679b1771-f61c-499c-811d-b960d68c7a8d"
      },
      "outputs": [],
      "source": [
        "print(t_symbol)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UC2tpiHOpgVu"
      },
      "outputs": [],
      "source": [
        "#t_symbol = [\"EURUSD\",\"AUDUSD\",\"GBPUSD\",\"USDCAD\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9Urbl8tJaFp",
        "outputId": "b6299a2a-23c2-42c6-8f42-2268afe6c8e7"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Filter the list to include only files, not directories\n",
        "# os.path.join is used to create a full path for isfile() to check\n",
        "files = [item for item in dir_contents]\n",
        "\n",
        "file_target = []\n",
        "test_target = []\n",
        "\n",
        "for filename in files:\n",
        "    for t_s in t_symbol:\n",
        "        if t_s in filename  and \"dbot.csv\" in filename:\n",
        "            print(filename)\n",
        "            file_target.append(filename)\n",
        "            test_target.append(filename.replace(\"dbot\",\"test\"))\n",
        "\n",
        "print(\"----------------------------------------------------\")\n",
        "\n",
        "print(len(file_target))\n",
        "print(len(test_target))\n",
        "train_dfs = []\n",
        "for f_t in file_target:\n",
        "    train_dfs.append(pd.read_csv(f_t))\n",
        "\n",
        "train_dfs_test = []\n",
        "for f_t in test_target:\n",
        "    train_dfs_test.append(pd.read_csv(f_t))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "94sFD1Kc29tr",
        "outputId": "c8aa60f1-e8b6-4aa1-b736-2bef8f7d1611"
      },
      "outputs": [],
      "source": [
        "display(train_dfs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tOE5gYlbhIFd",
        "outputId": "a9da9a6f-ec25-4759-e740-841cb535bf7f"
      },
      "outputs": [],
      "source": [
        "display(train_dfs_test[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-1MEa4L3HwH",
        "outputId": "4d48a4c1-6224-4026-a485-1aa764490f34"
      },
      "outputs": [],
      "source": [
        "print(train_dfs[0].values[:,-1:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "xnvfkDwKJaFp"
      },
      "outputs": [],
      "source": [
        "def create_sequences(data_scaled, seq_len, pred_steps = 5):\n",
        "    \"\"\"\n",
        "    data_scaled: np.array shaped (n_rows, n_features)\n",
        "    returns X (n_samples, seq_len, n_features), y (n_samples, n_features)\n",
        "    where y is the row immediately following the window.\n",
        "    \"\"\"\n",
        "    X, y = [], []\n",
        "    n_rows = data_scaled.shape[0]\n",
        "    for i in range(n_rows - seq_len - pred_steps + 1):\n",
        "        X.append(data_scaled[i:i+seq_len])\n",
        "        y.append(data_scaled[i+seq_len : i + seq_len+pred_steps, -1])\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "    return X, y\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "DqNMMybC2oHD"
      },
      "outputs": [],
      "source": [
        "n = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgfuQq2n2yc1",
        "outputId": "0784b3a8-b631-4e7f-8a48-75962084f30d"
      },
      "outputs": [],
      "source": [
        "m_label = file_target[n].replace(\"dbot.csv\",\"\")\n",
        "train_df = train_dfs[n]\n",
        "train_df_test = train_dfs_test[n]\n",
        "print(m_label)\n",
        "SEQ_LEN = 240 # length of input sequence (timesteps). Typical choices: 30, 60, 90\n",
        "n_rows, n_features = train_df.values.shape\n",
        "\n",
        "X, y = create_sequences(train_df.values, SEQ_LEN, 5)  # X: (n_samples, SEQ_LEN, n_features), y: (n_samples, n_features)\n",
        "X1, y1 = create_sequences(train_df.values, SEQ_LEN, 5)  # X: (n_samples, SEQ_LEN, n_features), y: (n_samples, n_features)\n",
        "\n",
        "n_samples = X.shape[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def preprocess_and_save_scalers(data_x, data_y, scaler_x_filename='scaler_x.joblib', scaler_y_filename='scaler_y.joblib'):\n",
        "    \"\"\"\n",
        "    Preprocesses 3D X and 2D Y data, scales them to a range of [0, 1],\n",
        "    and saves the fitted scalers.\n",
        "\n",
        "    Args:\n",
        "        data_x (np.ndarray): The input features, a 3D numpy array of shape (samples, timesteps, features).\n",
        "        data_y (np.ndarray): The target values, a 2D numpy array of shape (samples, output_dim).\n",
        "        scaler_x_filename (str): Filename to save the scaler for X data.\n",
        "        scaler_y_filename (str): Filename to save the scaler for Y data.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing the scaled X data (3D) and scaled Y data (2D).\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # --- Preprocess X data (3D) ---\n",
        "        # Reshape 3D data to 2D for scaler\n",
        "        original_shape_x = data_x.shape\n",
        "        data_x_reshaped = data_x.reshape(-1, original_shape_x[2])\n",
        "\n",
        "        # Initialize and fit the scaler for X\n",
        "        scaler_x = MinMaxScaler(feature_range=(0, 1))\n",
        "        scaled_x_reshaped = scaler_x.fit_transform(data_x_reshaped)\n",
        "\n",
        "        # Reshape the scaled data back to its original 3D shape\n",
        "        scaled_x = scaled_x_reshaped.reshape(original_shape_x)\n",
        "\n",
        "        # --- Preprocess Y data (2D) ---\n",
        "        scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
        "        scaled_y = scaler_y.fit_transform(data_y)\n",
        "\n",
        "        # --- Save the scalers ---\n",
        "        joblib.dump(scaler_x, scaler_x_filename)\n",
        "        joblib.dump(scaler_y, scaler_y_filename)\n",
        "        print(f\"Scaler for X saved to '{scaler_x_filename}'\")\n",
        "        print(f\"Scaler for Y saved to '{scaler_y_filename}'\")\n",
        "\n",
        "        return scaled_x, scaled_y\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred during preprocessing: {e}\")\n",
        "        return None, None\n",
        "\n",
        "def transform_data(data_x=None, data_y=None, scaler_x_filename='scaler_x.joblib', scaler_y_filename='scaler_y.joblib'):\n",
        "    \"\"\"\n",
        "    Transforms new 3D X and/or 2D Y data using saved scalers.\n",
        "\n",
        "    Args:\n",
        "        data_x (np.ndarray, optional): The new input features (3D numpy array). Defaults to None.\n",
        "        data_y (np.ndarray, optional): The new target values (2D numpy array). Defaults to None.\n",
        "        scaler_x_filename (str): Filename of the saved scaler for X data.\n",
        "        scaler_y_filename (str): Filename of the saved scaler for Y data.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing (scaled_x, scaled_y). Elements will be None if not provided.\n",
        "    \"\"\"\n",
        "    scaled_x = None\n",
        "    scaled_y = None\n",
        "\n",
        "    # Transform X data if provided\n",
        "    if data_x is not None:\n",
        "        if not os.path.exists(scaler_x_filename):\n",
        "            print(f\"Error: Scaler file for X not found at '{scaler_x_filename}'\")\n",
        "        else:\n",
        "            try:\n",
        "                scaler_x = joblib.load(scaler_x_filename)\n",
        "                original_shape_x = data_x.shape\n",
        "                # Ensure there's data to reshape\n",
        "                if original_shape_x[0] > 0:\n",
        "                    data_x_reshaped = data_x.reshape(-1, original_shape_x[2])\n",
        "                    scaled_x_reshaped = scaler_x.transform(data_x_reshaped)\n",
        "                    scaled_x = scaled_x_reshaped.reshape(original_shape_x)\n",
        "                else:\n",
        "                    # Handle empty array case\n",
        "                    scaled_x = np.array([]).reshape(original_shape_x)\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred during X transformation: {e}\")\n",
        "\n",
        "    # Transform Y data if provided\n",
        "    if data_y is not None:\n",
        "        if not os.path.exists(scaler_y_filename):\n",
        "            print(f\"Error: Scaler file for Y not found at '{scaler_y_filename}'\")\n",
        "        else:\n",
        "            try:\n",
        "                scaler_y = joblib.load(scaler_y_filename)\n",
        "                scaled_y = scaler_y.transform(data_y)\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred during Y transformation: {e}\")\n",
        "\n",
        "    return scaled_x, scaled_y\n",
        "\n",
        "\n",
        "def inverse_transform_data(scaled_x=None, scaled_y=None, scaler_x_filename='scaler_x.joblib', scaler_y_filename='scaler_y.joblib'):\n",
        "    \"\"\"\n",
        "    Inverse transforms scaled 3D X and/or 2D Y data to their original scale.\n",
        "\n",
        "    Args:\n",
        "        scaled_x (np.ndarray, optional): The scaled input features (3D numpy array). Defaults to None.\n",
        "        scaled_y (np.ndarray, optional): The scaled target values or predictions (2D numpy array). Defaults to None.\n",
        "        scaler_x_filename (str): Filename of the saved scaler for X data.\n",
        "        scaler_y_filename (str): Filename of the saved scaler for Y data.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing (inversed_x, inversed_y). Elements will be None if not provided.\n",
        "    \"\"\"\n",
        "    inversed_x = None\n",
        "    inversed_y = None\n",
        "\n",
        "    # Inverse transform X data if provided\n",
        "    if scaled_x is not None:\n",
        "        if not os.path.exists(scaler_x_filename):\n",
        "            print(f\"Error: Scaler file for X not found at '{scaler_x_filename}'\")\n",
        "        else:\n",
        "            try:\n",
        "                scaler_x = joblib.load(scaler_x_filename)\n",
        "                original_shape_x = scaled_x.shape\n",
        "                # Ensure there's data to reshape\n",
        "                if original_shape_x[0] > 0:\n",
        "                    scaled_x_reshaped = scaled_x.reshape(-1, original_shape_x[2])\n",
        "                    inversed_x_reshaped = scaler_x.inverse_transform(scaled_x_reshaped)\n",
        "                    inversed_x = inversed_x_reshaped.reshape(original_shape_x)\n",
        "                else:\n",
        "                    inversed_x = np.array([]).reshape(original_shape_x)\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred during X inverse transformation: {e}\")\n",
        "\n",
        "    # Inverse transform Y data if provided\n",
        "    if scaled_y is not None:\n",
        "        if not os.path.exists(scaler_y_filename):\n",
        "            print(f\"Error: Scaler file for Y not found at '{scaler_y_filename}'\")\n",
        "        else:\n",
        "            try:\n",
        "                scaler_y = joblib.load(scaler_y_filename)\n",
        "                inversed_y = scaler_y.inverse_transform(scaled_y)\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred during Y inverse transformation: {e}\")\n",
        "\n",
        "    return inversed_x, inversed_y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgr3stmT3oDg",
        "outputId": "80d849ed-9728-4fd8-fa96-1b2f778e1aef"
      },
      "outputs": [],
      "source": [
        "print(X[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plEgpMeQ3uvA",
        "outputId": "62472221-56a3-42b1-ff61-2b4b91bc4b19"
      },
      "outputs": [],
      "source": [
        "print(y[-2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "5j_wkyXD5s_s",
        "outputId": "13511d5b-1acf-450a-8259-13ee9a53e3e9"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0, shuffle=False)\n",
        "X_val, X_test, y_val,  y_test = train_test_split(X_test, y_test, test_size=0.01, random_state=0, shuffle=False)\n",
        "\n",
        "seq_len = X_train.shape[1]\n",
        "n_features = X_train.shape[2]\n",
        "output_dim = y_train.shape[1]\n",
        "\n",
        "i = Input(shape=(seq_len, n_features))\n",
        "X = Bidirectional(LSTM(200, return_sequences=True))(i)\n",
        "X = Bidirectional(LSTM(200, return_sequences=True))(X)\n",
        "X = Bidirectional(LSTM(200, return_sequences=True))(X)\n",
        "X = Bidirectional(LSTM(200))(X)\n",
        "#X = Dropout(0.5)(X)\n",
        "X = Dense(150, activation=\"relu\")(X)\n",
        "X = Dropout(0.5)(X)\n",
        "X = Dense(output_dim)(X)\n",
        "\n",
        "model = Model(i, X)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8q4twW84DPd",
        "outputId": "7749addf-c964-4642-d789-c97dd802c6c5"
      },
      "outputs": [],
      "source": [
        "\n",
        "es = EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True, verbose=2)\n",
        "rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=6, min_lr=1e-6, verbose=2)\n",
        "mc = ModelCheckpoint(m_label + 'lstm_best.keras', monitor='val_loss', save_best_only=True, verbose=2)\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='mse',\n",
        "              metrics=['mae',tf.keras.metrics.RootMeanSquaredError(),'mape','msle'])\n",
        "r = model.fit(\n",
        "  X_train, y_train,\n",
        "  validation_data=(X_val, y_val),\n",
        "  epochs=100,\n",
        "  #batch_size=1024,\n",
        "  callbacks=[es, rlr, mc ],\n",
        "  verbose=1\n",
        "\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN-5WQ-M4QOP"
      },
      "outputs": [],
      "source": [
        "plt.title(\"Loss on data\")\n",
        "plt.plot(r.history['loss'], label=\"loss\")\n",
        "plt.plot(r.history['val_loss'], label=\"val_loss\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.title(\"MAE on data\")\n",
        "plt.plot(r.history['mae'], label=\"mae\")\n",
        "plt.plot(r.history['val_mae'], label=\"val_mae\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.title(\"mape on data\")\n",
        "plt.plot(r.history['mape'], label=\"mape\")\n",
        "plt.plot(r.history['val_mape'], label=\"val_mape\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.title(\"msle on data\")\n",
        "plt.plot(r.history['msle'], label=\"msle\")\n",
        "plt.plot(r.history['val_msle'], label=\"val_msle\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "plt.title(\"root_mean_squared_error on data\")\n",
        "plt.plot(r.history['root_mean_squared_error'], label=\"root_mean_squared_error\")\n",
        "plt.plot(r.history['val_root_mean_squared_error'], label=\"val_root_mean_squared_error\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model = load_model(m_label + 'lstm_best.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "best_model.evaluate(X1[-100:],y1[-100:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = best_model.predict(X[-100:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(y[-2:], \" comparing to \", y_pred[-2:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"R^2 value for \", m_label)\n",
        "print(r2_score(y[-100:], y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred = best_model.predict(X1)\n",
        "print(\"R^2 value for test \", m_label)\n",
        "print(r2_score(y1, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(y1[-1], \" comparing to \", y_pred[-1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y_test[:, 0], label='Actual Close Price', color='blue')\n",
        "plt.plot(y_pred[:, 0], label='Predicted Close Price', color='red', linestyle='--')\n",
        "plt.title('Actual vs. Predicted Close Price')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Close Price')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('actual_vs_predicted.png')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(y1[:, 0], label='Actual Close Price', color='blue')\n",
        "plt.plot(y_pred[:, 0], label='Predicted Close Price', color='red', linestyle='--')\n",
        "plt.title('Actual vs. Predicted Close Price Test')\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Close Price')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig('actual_vs_predicted.png')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
